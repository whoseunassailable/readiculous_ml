{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb70d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading data...\n",
      "Initial shape: (151774, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dw/fn12lc3x2b317ydc5b70v2340000gn/T/ipykernel_2630/3276684373.py:15: DtypeWarning: Columns (1,3,4,8,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/Users/whoseunassailable/Documents/coding_projects/college_projects/readiculous/data/processed/combined_books.csv\")\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['genres']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dw/fn12lc3x2b317ydc5b70v2340000gn/T/ipykernel_2630/3276684373.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/whoseunassailable/Documents/coding_projects/college_projects/readiculous/data/processed/combined_books.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mInitial shape: \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Drop rows with missing critical fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'author'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'desc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'genres'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'author'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Filter garbage or uninformative entries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6666\u001b[0m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6667\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6668\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6669\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6670\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6671\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6673\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ['genres']"
     ]
    }
   ],
   "source": [
    "# Book Recommendation System: Unified Pipeline (Refactored)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "import ast\n",
    "\n",
    "# ------------------------------\n",
    "# Step 1: Data Loading & Cleaning\n",
    "# ------------------------------\n",
    "print(\"[INFO] Loading data...\")\n",
    "df = pd.read_csv(\"/Users/whoseunassailable/Documents/coding_projects/college_projects/readiculous/data/processed/combined_books.csv\")\n",
    "print(f\"Initial shape: {df.shape}\")\n",
    "\n",
    "# Drop rows with missing critical fields\n",
    "df.dropna(subset=['title', 'author', 'desc', 'genres'], inplace=True)\n",
    "df.drop_duplicates(subset=['title', 'author'], inplace=True)\n",
    "\n",
    "# Filter garbage or uninformative entries\n",
    "def is_valid_description(desc):\n",
    "    invalids = ['.', 'No', 'no', 'PB', 'pB', 'P.B.']\n",
    "    return not any(desc.strip() == val for val in invalids)\n",
    "\n",
    "df = df[df['desc'].apply(lambda x: isinstance(x, str) and is_valid_description(x))]\n",
    "df = df[df['title'].apply(lambda x: isinstance(x, str) and len(x) > 2 and not x.isdigit())]\n",
    "df = df[df['author'].apply(lambda x: isinstance(x, str) and len(x.strip()) > 0)]\n",
    "\n",
    "# Normalize text columns\n",
    "df['author'] = df['author'].str.strip().str.lower()\n",
    "df['desc'] = df['desc'].str.strip().str.lower()\n",
    "df['genres'] = df['genres'].str.strip().str.lower()\n",
    "\n",
    "# Parse genres to lists\n",
    "df['genres_list'] = df['genres'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) and x.startswith('[') else [])\n",
    "\n",
    "# ------------------------------\n",
    "# Step 2: Feature Engineering (Combined Text)\n",
    "# ------------------------------\n",
    "def create_combined_text(row):\n",
    "    return f\"{row['title']} {row['author']} {row['desc']} {' '.join(row['genres_list'])}\"\n",
    "\n",
    "print(\"[INFO] Creating combined_text feature...\")\n",
    "df['combined_text'] = df.apply(create_combined_text, axis=1)\n",
    "df.to_csv(\"cleaned_books.csv\", index=False)\n",
    "\n",
    "# ------------------------------\n",
    "# Step 3: TF-IDF Vectorization\n",
    "# ------------------------------\n",
    "print(\"[INFO] Applying TF-IDF vectorization...\")\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_matrix = tfidf.fit_transform(df['combined_text'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# ------------------------------\n",
    "# Step 4: Genre-Based Filtering\n",
    "# ------------------------------\n",
    "def get_genre_recommendations(book_title, top_n=5):\n",
    "    idx = df[df['title'].str.lower() == book_title.lower()].index\n",
    "    if len(idx) == 0:\n",
    "        return []\n",
    "    idx = idx[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:top_n+1]\n",
    "    return df.iloc[[i[0] for i in sim_scores]][['title', 'author', 'genres']]\n",
    "\n",
    "# ------------------------------\n",
    "# Step 5: Collaborative Filtering (SVD)\n",
    "# ------------------------------\n",
    "print(\"[INFO] Running Collaborative Filtering with Surprise SVD...\")\n",
    "\n",
    "ratings = pd.DataFrame({\n",
    "    'user_id': np.random.randint(1, 100, 1000),\n",
    "    'title': np.random.choice(df['title'], 1000),\n",
    "    'rating': np.random.randint(1, 6, 1000)\n",
    "})\n",
    "\n",
    "ratings = ratings.merge(df[['title']], on='title')\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['user_id', 'title', 'rating']], reader)\n",
    "\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=3, verbose=True)\n",
    "\n",
    "# ------------------------------\n",
    "# Example Usage\n",
    "# ------------------------------\n",
    "print(\"\\n[INFO] Sample Recommendations for 'Harry Potter'\")\n",
    "print(get_genre_recommendations(\"Harry Potter\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a56262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
